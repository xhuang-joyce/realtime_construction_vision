# ğŸ¤– True Realtime AI Conversation Agent

åŸºäº OpenAI Realtime API (2025å¹´8æœˆ28æ—¥æ›´æ–°) æ„å»ºçš„**çœŸæ­£å®æ—¶å¯¹è¯ç³»ç»Ÿ**ï¼Œæ”¯æŒå›¾åƒè¾“å…¥å’ŒæŒç»­è¯­éŸ³äº¤äº’ã€‚

## ğŸŒŸ ä»€ä¹ˆæ˜¯çœŸæ­£çš„å®æ—¶å¯¹è¯ä»£ç†ï¼Ÿ

ä¸ä¼ ç»Ÿçš„"å‘é€å›¾ç‰‡â†’ç­‰å¾…å›å¤"ç³»ç»Ÿä¸åŒï¼Œè¿™æ˜¯ä¸€ä¸ª**çœŸæ­£çš„å®æ—¶å¯¹è¯ä»£ç†**ï¼š

### âœ¨ æ ¸å¿ƒç‰¹æ€§
- ğŸ¤ **æŒç»­è¯­éŸ³å¯¹è¯**ï¼šç”¨æˆ·å¯ä»¥éšæ—¶è¯´è¯ï¼ŒAI éšæ—¶å›åº”
- ğŸ‘ï¸ **è§†è§‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šAI èƒ½çœ‹åˆ°ä½ çš„ç¯å¢ƒï¼Œå¹¶åœ¨å¯¹è¯ä¸­å¼•ç”¨
- ğŸ§  **å¤šæ¨¡æ€èåˆ**ï¼šè¯­éŸ³ã€è§†è§‰ã€æ–‡æœ¬æ— ç¼ç»“åˆ
- âš¡ **çœŸå®æ—¶äº¤äº’**ï¼šæ— éœ€ç­‰å¾…ï¼Œè‡ªç„¶å¯¹è¯æµç¨‹
- ğŸ¯ **æ‰‹åŠ¿ç†è§£**ï¼šä¸“é—¨ä¼˜åŒ–ç”¨äºç†è§£äººç±»æ‰‹åŠ¿å’Œèº«ä½“è¯­è¨€

### ğŸ†š ä¸ä¼ ç»Ÿç³»ç»Ÿçš„åŒºåˆ«

**ä¼ ç»Ÿç³»ç»Ÿ**ï¼ˆç±»ä¼¼å½“å‰å¤§å¤šæ•°å®ç°ï¼‰ï¼š
```
ç”¨æˆ·æ‹ç…§ â†’ å‘é€API â†’ ç­‰å¾…å›å¤ â†’ æ’­æ”¾éŸ³é¢‘ â†’ ç»“æŸ
```

**çœŸæ­£çš„å®æ—¶ä»£ç†**ï¼ˆæœ¬é¡¹ç›®ï¼‰ï¼š
```
æŒç»­ç›‘å¬ â† â†’ æŒç»­çœ‹è§ â† â†’ æŒç»­å¯¹è¯ â† â†’ æŒç»­ç†è§£
```

## ğŸŒŸ Features

- **ğŸ¤ Voice Interaction**: Speak naturally to the AI while it watches through your camera
- **ğŸ“¹ Real-time Video Analysis**: Continuous analysis of camera feed with focus on human gestures
- **ğŸ¤– Intelligent Responses**: AI provides both spoken audio and text responses
- **ğŸ¯ Gesture Understanding**: Expert-level analysis of body language and human gestures
- **âš¡ Real-time Processing**: Low-latency interaction using OpenAI's Realtime API
- **ğŸ”„ Multimodal Integration**: Seamless combination of vision and voice input

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Update your API key in `.env` file:
```
OPENAI_API_KEY=your_actual_api_key_here
```

3. Run the application:
```bash
python main.py
```

## ğŸš€ Quick Start

### Voice Interaction Mode (Recommended)
```bash
# Start with voice interaction - you can talk to the AI!
python main.py --realtime

# Or use the launcher
python launch.py --voice
```

### Vision-Only Mode
```bash
# Traditional mode - AI analyzes camera without voice input
python main.py --vision-only

# Or use the launcher  
python launch.py --vision
```

### Testing
```bash
# Test all components
python test_components.py

# Test voice interaction specifically
python test_multimodal.py

# List available devices
python main.py --list-devices
```

## ğŸ’¬ How to Use

### Voice Interaction Mode:
1. The AI can see through your camera and hear your voice
2. Speak naturally - try phrases like:
   - "Hello, what do you see?"
   - "Can you describe what's in front of you?"
   - "What gesture am I making?" (while waving or pointing)
   - "Tell me about the scene"
3. The AI will respond with both voice and text
4. Have a natural conversation while it watches!

### Vision-Only Mode:
- The AI analyzes your camera feed continuously
- Provides automated descriptions with text-to-speech
- Focus on gesture and body language analysis
- No voice input required

## System Requirements

- Python 3.8+
- Webcam/Camera
- Internet connection for OpenAI API
- Audio output capability